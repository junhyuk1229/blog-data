{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "rfCom8FJlgv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "SLA3d15aapQq"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Model"
      ],
      "metadata": {
        "id": "lLKDQ7Yrb5Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Here you can see that the linear transformation uses\n",
        "the weight matrix and bias matrix.\n",
        "'''\n",
        "model = nn.Linear(1, 1)\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFZOBtBbbseE",
        "outputId": "ebb6c719-b8b2-46b4-af15-52931a708780"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[0.9068]])), ('bias', tensor([0.0285]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This linear transformation takes a 10 input and returns a 5\n",
        "output. When checking the values in the transformation, the weight's\n",
        "shape is (5, 10) but the input is (x, 10) so it might be confusing.\n",
        "The bias always has the same size as the output dim.\n",
        "'''\n",
        "model = nn.Linear(10, 5)\n",
        "for i, v in model.state_dict().items():\n",
        "    print(f\"index: {i}\\t\\tshape: {v.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI3eUTG4ginr",
        "outputId": "46e92dc6-2a31-4f56-afb6-f08edfd2a5b2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index: weight\t\tshape: torch.Size([5, 10])\n",
            "index: bias\t\tshape: torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "As you can see the result is (1, 10) * (10, 5) = (1 * 5)\n",
        "'''\n",
        "x = torch.rand(1, 10)\n",
        "y_hat = model(x)\n",
        "print(f\"Input Shape: {x.shape}\")\n",
        "print(f\"Output Shape: {y_hat.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHpCBqaRkLJU",
        "outputId": "45d61ad7-e429-44c9-8899-a865732dc411"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: torch.Size([1, 10])\n",
            "Output Shape: torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "If the bias option is false the bias is not used\n",
        "'''\n",
        "model = nn.Linear(10, 5, bias=False)\n",
        "for i, v in model.state_dict().items():\n",
        "    print(f\"index: {i}\\t\\tshape: {v.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DbmyZXRhFhC",
        "outputId": "92e93e6a-658a-4726-bedd-2d36aefb2973"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index: weight\t\tshape: torch.Size([5, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "If a dtype is specified it will use that dtype.\n",
        "If there is not a dtype used then it will use the default dtype.\n",
        "In this case the default dtype is torch.float32\n",
        "'''\n",
        "model = nn.Linear(10, 5, dtype=torch.float32)\n",
        "for i, v in model.state_dict().items():\n",
        "    print(f\"index: {i}\\t\\tshape: {v.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOyzbRlyhNK8",
        "outputId": "552e0c08-18f1-4ffc-cfd9-47059b07a52d"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index: weight\t\tshape: torch.Size([5, 10])\n",
            "index: bias\t\tshape: torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "You can use the .weight and .bias to get the matrix for each\n",
        "'''\n",
        "model = nn.Linear(10, 5, dtype=torch.float32)\n",
        "print(f\"Model Weight: {model.weight.shape}\")\n",
        "print(f\"Model Bias: {model.bias.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy1c-kRYiCTA",
        "outputId": "b749a554-20a8-4e2f-d214-307995384acb"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Weight: torch.Size([5, 10])\n",
            "Model Bias: torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Model"
      ],
      "metadata": {
        "id": "JmYzNs3ZgY5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(40).unsqueeze(1) * 40\n",
        "print(x.shape)\n",
        "print(x.squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfp1RQ-IavSn",
        "outputId": "1cfa6a92-318d-4734-c97b-fdcbc16f3ac2"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40, 1])\n",
            "tensor([17.0229, 31.7264,  8.4700,  0.2274, 34.4207, 31.8699, 36.1829, 17.4096,\n",
            "        28.1539,  0.6171, 20.2019, 34.8220, 10.4346,  4.6249, 14.6462, 33.1293,\n",
            "        24.0936, 10.6691,  5.8224, 13.5482, 28.6915, 27.1263, 24.6706,  3.0260,\n",
            "         4.1184, 10.8148, 10.7229, 37.2049, 31.4229, 20.5013, 32.7484,  6.4798,\n",
            "         1.6369, 26.2695, 10.7635,  0.6334, 32.7217,  2.3402, 11.6497, 12.9401])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = 4 * x + 3\n",
        "print(y.shape)\n",
        "print(y.squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJZ3ZL_hbNdR",
        "outputId": "187c1286-06b1-4923-fd07-ee313d647169"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40, 1])\n",
            "tensor([ 71.0914, 129.9054,  36.8801,   3.9094, 140.6829, 130.4798, 147.7317,\n",
            "         72.6385, 115.6158,   5.4684,  83.8074, 142.2882,  44.7383,  21.4998,\n",
            "         61.5850, 135.5173,  99.3744,  45.6765,  26.2897,  57.1929, 117.7659,\n",
            "        111.5051, 101.6826,  15.1040,  19.4735,  46.2594,  45.8917, 151.8198,\n",
            "        128.6917,  85.0052, 133.9936,  28.9193,   9.5478, 108.0779,  46.0538,\n",
            "          5.5336, 133.8868,  12.3607,  49.5988,  54.7603])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(1, 1)"
      ],
      "metadata": {
        "id": "phfAj6uIgkej"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model(x)\n",
        "print(y_hat.shape)\n",
        "print(y_hat.squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQIPcEBib97n",
        "outputId": "1a4b20ac-37af-4dd5-d938-454bd17a3845"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40, 1])\n",
            "tensor([-1.2825e+01, -2.4348e+01, -6.1223e+00,  3.3737e-01, -2.6459e+01,\n",
            "        -2.4460e+01, -2.7840e+01, -1.3128e+01, -2.1548e+01,  3.1934e-02,\n",
            "        -1.5316e+01, -2.6774e+01, -7.6619e+00, -3.1090e+00, -1.0962e+01,\n",
            "        -2.5447e+01, -1.8366e+01, -7.8457e+00, -4.0474e+00, -1.0102e+01,\n",
            "        -2.1970e+01, -2.0743e+01, -1.8818e+01, -1.8559e+00, -2.7120e+00,\n",
            "        -7.9599e+00, -7.8879e+00, -2.8641e+01, -2.4110e+01, -1.5551e+01,\n",
            "        -2.5149e+01, -4.5626e+00, -7.6730e-01, -2.0071e+01, -7.9196e+00,\n",
            "         1.9148e-02, -2.5128e+01, -1.3184e+00, -8.6141e+00, -9.6254e+00],\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if y_hat.shape == y.shape:\n",
        "    print(\"The result has the same shape\")\n",
        "else:\n",
        "    print(\"The result has a different shape\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIDCmGncdTiK",
        "outputId": "d28ca295-7863-46b4-90a0-b80fed28a4cb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result has the same shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "ymTBsn_TeMVi"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), 0.05)"
      ],
      "metadata": {
        "id": "Gin1QEn4fKz_"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    y_hat = model(x)\n",
        "    \n",
        "    loss = loss_fn(y_hat, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    print(f\"epoch: {epoch + 1}:\\t\\tloss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n19056uqeedY",
        "outputId": "3d1e0abf-2e71-40f4-90c5-efcf84d1abed"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1:\t\tloss: 10996.8740234375\n",
            "epoch: 2:\t\tloss: 10764.009765625\n",
            "epoch: 3:\t\tloss: 10533.7060546875\n",
            "epoch: 4:\t\tloss: 10306.0048828125\n",
            "epoch: 5:\t\tloss: 10080.947265625\n",
            "epoch: 6:\t\tloss: 9858.5732421875\n",
            "epoch: 7:\t\tloss: 9638.9208984375\n",
            "epoch: 8:\t\tloss: 9422.0263671875\n",
            "epoch: 9:\t\tloss: 9207.923828125\n",
            "epoch: 10:\t\tloss: 8996.646484375\n",
            "epoch: 11:\t\tloss: 8788.2216796875\n",
            "epoch: 12:\t\tloss: 8582.6806640625\n",
            "epoch: 13:\t\tloss: 8380.046875\n",
            "epoch: 14:\t\tloss: 8180.3447265625\n",
            "epoch: 15:\t\tloss: 7983.5947265625\n",
            "epoch: 16:\t\tloss: 7789.81494140625\n",
            "epoch: 17:\t\tloss: 7599.0224609375\n",
            "epoch: 18:\t\tloss: 7411.2294921875\n",
            "epoch: 19:\t\tloss: 7226.4501953125\n",
            "epoch: 20:\t\tloss: 7044.6904296875\n",
            "epoch: 21:\t\tloss: 6865.95703125\n",
            "epoch: 22:\t\tloss: 6690.2568359375\n",
            "epoch: 23:\t\tloss: 6517.58984375\n",
            "epoch: 24:\t\tloss: 6347.955078125\n",
            "epoch: 25:\t\tloss: 6181.35107421875\n",
            "epoch: 26:\t\tloss: 6017.77294921875\n",
            "epoch: 27:\t\tloss: 5857.212890625\n",
            "epoch: 28:\t\tloss: 5699.66259765625\n",
            "epoch: 29:\t\tloss: 5545.11181640625\n",
            "epoch: 30:\t\tloss: 5393.5458984375\n",
            "epoch: 31:\t\tloss: 5244.9521484375\n",
            "epoch: 32:\t\tloss: 5099.31298828125\n",
            "epoch: 33:\t\tloss: 4956.6103515625\n",
            "epoch: 34:\t\tloss: 4816.82470703125\n",
            "epoch: 35:\t\tloss: 4679.9345703125\n",
            "epoch: 36:\t\tloss: 4545.91845703125\n",
            "epoch: 37:\t\tloss: 4414.7509765625\n",
            "epoch: 38:\t\tloss: 4286.4072265625\n",
            "epoch: 39:\t\tloss: 4160.8603515625\n",
            "epoch: 40:\t\tloss: 4038.08203125\n",
            "epoch: 41:\t\tloss: 3918.04541015625\n",
            "epoch: 42:\t\tloss: 3800.719482421875\n",
            "epoch: 43:\t\tloss: 3686.073486328125\n",
            "epoch: 44:\t\tloss: 3574.076904296875\n",
            "epoch: 45:\t\tloss: 3464.696044921875\n",
            "epoch: 46:\t\tloss: 3357.89892578125\n",
            "epoch: 47:\t\tloss: 3253.65185546875\n",
            "epoch: 48:\t\tloss: 3151.91943359375\n",
            "epoch: 49:\t\tloss: 3052.668212890625\n",
            "epoch: 50:\t\tloss: 2955.862548828125\n",
            "epoch: 51:\t\tloss: 2861.466064453125\n",
            "epoch: 52:\t\tloss: 2769.44287109375\n",
            "epoch: 53:\t\tloss: 2679.75732421875\n",
            "epoch: 54:\t\tloss: 2592.3720703125\n",
            "epoch: 55:\t\tloss: 2507.25\n",
            "epoch: 56:\t\tloss: 2424.35400390625\n",
            "epoch: 57:\t\tloss: 2343.64697265625\n",
            "epoch: 58:\t\tloss: 2265.09130859375\n",
            "epoch: 59:\t\tloss: 2188.649169921875\n",
            "epoch: 60:\t\tloss: 2114.283447265625\n",
            "epoch: 61:\t\tloss: 2041.9560546875\n",
            "epoch: 62:\t\tloss: 1971.630126953125\n",
            "epoch: 63:\t\tloss: 1903.267333984375\n",
            "epoch: 64:\t\tloss: 1836.830810546875\n",
            "epoch: 65:\t\tloss: 1772.2828369140625\n",
            "epoch: 66:\t\tloss: 1709.5863037109375\n",
            "epoch: 67:\t\tloss: 1648.704345703125\n",
            "epoch: 68:\t\tloss: 1589.599853515625\n",
            "epoch: 69:\t\tloss: 1532.2362060546875\n",
            "epoch: 70:\t\tloss: 1476.576416015625\n",
            "epoch: 71:\t\tloss: 1422.5845947265625\n",
            "epoch: 72:\t\tloss: 1370.2252197265625\n",
            "epoch: 73:\t\tloss: 1319.461669921875\n",
            "epoch: 74:\t\tloss: 1270.259033203125\n",
            "epoch: 75:\t\tloss: 1222.582275390625\n",
            "epoch: 76:\t\tloss: 1176.396484375\n",
            "epoch: 77:\t\tloss: 1131.667236328125\n",
            "epoch: 78:\t\tloss: 1088.360107421875\n",
            "epoch: 79:\t\tloss: 1046.4415283203125\n",
            "epoch: 80:\t\tloss: 1005.8782958984375\n",
            "epoch: 81:\t\tloss: 966.6373291015625\n",
            "epoch: 82:\t\tloss: 928.6864013671875\n",
            "epoch: 83:\t\tloss: 891.9927978515625\n",
            "epoch: 84:\t\tloss: 856.5250244140625\n",
            "epoch: 85:\t\tloss: 822.2516479492188\n",
            "epoch: 86:\t\tloss: 789.1417236328125\n",
            "epoch: 87:\t\tloss: 757.1650390625\n",
            "epoch: 88:\t\tloss: 726.2916259765625\n",
            "epoch: 89:\t\tloss: 696.4918212890625\n",
            "epoch: 90:\t\tloss: 667.7361450195312\n",
            "epoch: 91:\t\tloss: 639.9962158203125\n",
            "epoch: 92:\t\tloss: 613.2437744140625\n",
            "epoch: 93:\t\tloss: 587.4515380859375\n",
            "epoch: 94:\t\tloss: 562.5919799804688\n",
            "epoch: 95:\t\tloss: 538.6385498046875\n",
            "epoch: 96:\t\tloss: 515.5646362304688\n",
            "epoch: 97:\t\tloss: 493.3448181152344\n",
            "epoch: 98:\t\tloss: 471.95361328125\n",
            "epoch: 99:\t\tloss: 451.3662109375\n",
            "epoch: 100:\t\tloss: 431.5581970214844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-WdHAdk7e0UD"
      },
      "execution_count": 110,
      "outputs": []
    }
  ]
}